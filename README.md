# STFC Summer School 2019: Apache Spark

Welcome to the Apache Spark Workshop! This repository contains the material for the the STFC Summer School 2019. The session will take place on Thursday 25th July. 

### Prerequis

* Basic knowledge of Python
* Basic knowledge of Docker

### Goals of the workshop

*  Learning the basics of cluster computing, and the big data challenges in modern science.
- Learning how to integrate scientific tools into Apache Spark, and how to perform efficient analysis on large volumes of data.


### Timetable

- Session 1: Introduction [presentation, exercises]
	- I will review the landscape of cluster computing by addressing some of the most pressing questions today: what is cluster computing? What does it mean working in a distributed environment? What are the data and computing challenges that science is facing nowadays, and how we can tackle those? I will also introduce Apache Spark, a cluster computing framework for analysing large datasets that proved successful in the industry. I will specifically focus on the Apache Spark SQL module and DataFrames API, and we will start practicing through a series of simple exercises.
- Session 2: Apache Spark for science [presentation, exercises]
	- In this session, we will use the Apache Spark Python API (PySpark) and learn on concrete examples how to interface and play with popular scientific libraries (Numpy, Pandas, ...).
- Session 3: Going beyond [presentation, exercises]
	- For the last section, we will see how to use the Spark UI to gain insights on how Apache Spark is working under the hood, and we will learn how to perform an efficient early stage debugging. We will finally end the module with real-life applications.